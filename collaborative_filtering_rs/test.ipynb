{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('D:\\FashionAI- RS\\submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_7592\\3925576894.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  len(df.iloc[0][1].split())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.iloc[0][1].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...</td>\n",
       "      <td>0924243001 0781758057 0751471001 0309864012 09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...</td>\n",
       "      <td>0924243001 0751471001 0918522001 0924243002 04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>0924243001 0914319002 0751471001 0894668003 09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...</td>\n",
       "      <td>0924243001 0751471001 0918522001 0924243002 04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...</td>\n",
       "      <td>0924243001 0751471001 0918522001 0924243002 04...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_id  \\\n",
       "0  00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...   \n",
       "1  0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...   \n",
       "2  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...   \n",
       "3  00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...   \n",
       "4  00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...   \n",
       "\n",
       "                                          prediction  \n",
       "0  0924243001 0781758057 0751471001 0309864012 09...  \n",
       "1  0924243001 0751471001 0918522001 0924243002 04...  \n",
       "2  0924243001 0914319002 0751471001 0894668003 09...  \n",
       "3  0924243001 0751471001 0918522001 0924243002 04...  \n",
       "4  0924243001 0751471001 0918522001 0924243002 04...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pickle\n",
    "# import csv\n",
    "\n",
    "# def pickle_to_csv(pickle_file, csv_file):\n",
    "#     # Step 1: Load data from pickle file\n",
    "#     with open(pickle_file, 'rb') as f:\n",
    "#         data = pickle.load(f)\n",
    "    \n",
    "#     # Step 2: Convert data to CSV format\n",
    "#     # Assuming the data is a NumPy array\n",
    "#     headers = [f\"feature_{i}\" for i in range(data.shape[1])]  # Assuming each column represents a feature\n",
    "#     with open(csv_file, 'w', newline='') as f:\n",
    "#         writer = csv.writer(f)\n",
    "#         writer.writerow(headers)\n",
    "#         writer.writerows(data)\n",
    "\n",
    "# # Usage example:\n",
    "# pickle_to_csv('D:/FashionAI- RS/articles_latent_matrix.pkl', 'articles_latent_matrix.csv')\n",
    "\n",
    "\n",
    "\n",
    "positive_transactions_df = pd.read_csv('D:/FashionAI- RS/positive_transactions.csv')\n",
    "\n",
    "articles_latent_matrix_np = pd.read_csv('D:/FashionAI- RS/collaborative_filtering_rs/articles_latent_matrix.csv')\n",
    "positive_transactions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1371980, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_transactions_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_990</th>\n",
       "      <th>feature_991</th>\n",
       "      <th>feature_992</th>\n",
       "      <th>feature_993</th>\n",
       "      <th>feature_994</th>\n",
       "      <th>feature_995</th>\n",
       "      <th>feature_996</th>\n",
       "      <th>feature_997</th>\n",
       "      <th>feature_998</th>\n",
       "      <th>feature_999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.523597</td>\n",
       "      <td>-0.908746</td>\n",
       "      <td>0.366298</td>\n",
       "      <td>-0.698213</td>\n",
       "      <td>0.040383</td>\n",
       "      <td>2.169825</td>\n",
       "      <td>0.774345</td>\n",
       "      <td>0.067102</td>\n",
       "      <td>-0.261164</td>\n",
       "      <td>-0.025457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534467</td>\n",
       "      <td>1.062947</td>\n",
       "      <td>0.395399</td>\n",
       "      <td>0.957966</td>\n",
       "      <td>1.141902</td>\n",
       "      <td>0.137718</td>\n",
       "      <td>-0.943270</td>\n",
       "      <td>-0.142768</td>\n",
       "      <td>-0.051983</td>\n",
       "      <td>-0.435125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.101637</td>\n",
       "      <td>0.185542</td>\n",
       "      <td>-0.492651</td>\n",
       "      <td>0.024842</td>\n",
       "      <td>0.227164</td>\n",
       "      <td>0.150778</td>\n",
       "      <td>0.578980</td>\n",
       "      <td>0.537266</td>\n",
       "      <td>-0.912290</td>\n",
       "      <td>-0.913828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.460668</td>\n",
       "      <td>-0.407041</td>\n",
       "      <td>-0.410582</td>\n",
       "      <td>-0.211834</td>\n",
       "      <td>0.268991</td>\n",
       "      <td>-0.108093</td>\n",
       "      <td>0.585754</td>\n",
       "      <td>-0.255044</td>\n",
       "      <td>0.456059</td>\n",
       "      <td>-0.387659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.090420</td>\n",
       "      <td>-0.125948</td>\n",
       "      <td>0.067930</td>\n",
       "      <td>0.466732</td>\n",
       "      <td>-0.365643</td>\n",
       "      <td>0.481056</td>\n",
       "      <td>0.689512</td>\n",
       "      <td>-0.839367</td>\n",
       "      <td>0.447165</td>\n",
       "      <td>-0.210808</td>\n",
       "      <td>...</td>\n",
       "      <td>0.778598</td>\n",
       "      <td>0.112142</td>\n",
       "      <td>-0.057129</td>\n",
       "      <td>0.154778</td>\n",
       "      <td>0.584196</td>\n",
       "      <td>-0.079730</td>\n",
       "      <td>-0.188274</td>\n",
       "      <td>0.118152</td>\n",
       "      <td>-0.339338</td>\n",
       "      <td>-0.095529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.415906</td>\n",
       "      <td>0.888904</td>\n",
       "      <td>0.849201</td>\n",
       "      <td>0.803405</td>\n",
       "      <td>0.134218</td>\n",
       "      <td>-0.145065</td>\n",
       "      <td>0.286585</td>\n",
       "      <td>-1.468780</td>\n",
       "      <td>-0.099359</td>\n",
       "      <td>0.637025</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.277569</td>\n",
       "      <td>0.740443</td>\n",
       "      <td>0.912773</td>\n",
       "      <td>2.071180</td>\n",
       "      <td>1.758314</td>\n",
       "      <td>0.452126</td>\n",
       "      <td>0.306712</td>\n",
       "      <td>0.924382</td>\n",
       "      <td>-0.237099</td>\n",
       "      <td>0.015992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.272878</td>\n",
       "      <td>-0.839160</td>\n",
       "      <td>0.241769</td>\n",
       "      <td>0.286933</td>\n",
       "      <td>-0.057294</td>\n",
       "      <td>-0.243922</td>\n",
       "      <td>0.402757</td>\n",
       "      <td>-0.314359</td>\n",
       "      <td>-0.709894</td>\n",
       "      <td>-0.981846</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.330101</td>\n",
       "      <td>-0.189698</td>\n",
       "      <td>0.072118</td>\n",
       "      <td>-0.506425</td>\n",
       "      <td>0.332933</td>\n",
       "      <td>-0.579324</td>\n",
       "      <td>0.050444</td>\n",
       "      <td>-0.415160</td>\n",
       "      <td>0.297512</td>\n",
       "      <td>0.503568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0  -0.523597  -0.908746   0.366298  -0.698213   0.040383   2.169825   \n",
       "1  -0.101637   0.185542  -0.492651   0.024842   0.227164   0.150778   \n",
       "2  -0.090420  -0.125948   0.067930   0.466732  -0.365643   0.481056   \n",
       "3  -0.415906   0.888904   0.849201   0.803405   0.134218  -0.145065   \n",
       "4  -1.272878  -0.839160   0.241769   0.286933  -0.057294  -0.243922   \n",
       "\n",
       "   feature_6  feature_7  feature_8  feature_9  ...  feature_990  feature_991  \\\n",
       "0   0.774345   0.067102  -0.261164  -0.025457  ...     0.534467     1.062947   \n",
       "1   0.578980   0.537266  -0.912290  -0.913828  ...     0.460668    -0.407041   \n",
       "2   0.689512  -0.839367   0.447165  -0.210808  ...     0.778598     0.112142   \n",
       "3   0.286585  -1.468780  -0.099359   0.637025  ...    -0.277569     0.740443   \n",
       "4   0.402757  -0.314359  -0.709894  -0.981846  ...    -0.330101    -0.189698   \n",
       "\n",
       "   feature_992  feature_993  feature_994  feature_995  feature_996  \\\n",
       "0     0.395399     0.957966     1.141902     0.137718    -0.943270   \n",
       "1    -0.410582    -0.211834     0.268991    -0.108093     0.585754   \n",
       "2    -0.057129     0.154778     0.584196    -0.079730    -0.188274   \n",
       "3     0.912773     2.071180     1.758314     0.452126     0.306712   \n",
       "4     0.072118    -0.506425     0.332933    -0.579324     0.050444   \n",
       "\n",
       "   feature_997  feature_998  feature_999  \n",
       "0    -0.142768    -0.051983    -0.435125  \n",
       "1    -0.255044     0.456059    -0.387659  \n",
       "2     0.118152    -0.339338    -0.095529  \n",
       "3     0.924382    -0.237099     0.015992  \n",
       "4    -0.415160     0.297512     0.503568  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_latent_matrix_np.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastparquetNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached fastparquet-2024.2.0-cp310-cp310-win_amd64.whl (670 kB)\n",
      "Requirement already satisfied: packaging in d:\\fashionai- rs\\venv\\lib\\site-packages (from fastparquet) (24.0)\n",
      "Requirement already satisfied: numpy>=1.20.3 in d:\\fashionai- rs\\venv\\lib\\site-packages (from fastparquet) (1.26.4)\n",
      "Collecting cramjam>=2.3\n",
      "  Using cached cramjam-2.8.3-cp310-none-win_amd64.whl (1.6 MB)\n",
      "Requirement already satisfied: pandas>=1.5.0 in d:\\fashionai- rs\\venv\\lib\\site-packages (from fastparquet) (2.2.2)\n",
      "Requirement already satisfied: fsspec in d:\\fashionai- rs\\venv\\lib\\site-packages (from fastparquet) (2024.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\fashionai- rs\\venv\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\fashionai- rs\\venv\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\fashionai- rs\\venv\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\fashionai- rs\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.16.0)\n",
      "Installing collected packages: cramjam, fastparquet\n",
      "Successfully installed cramjam-2.8.3 fastparquet-2024.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'd:\\FashionAI- RS\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import fastparquet\n",
    "\n",
    "# Read CSV file\n",
    "# positive_transactions_df = pd.read_csv('positive_transactions_df.csv')\n",
    "\n",
    "# Convert to Parquet format\n",
    "positive_transactions_df.to_parquet('positive_transactions.parquet', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 most similar users for customer A based on their interactions:\n",
      "[457319, 457321, 457322]\n"
     ]
    }
   ],
   "source": [
    "# 12 items needed?\n",
    "\n",
    "# Input -> userId, productsPurchased\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "def similar_user(userID, user_articles, positive_transactions_parquet, n_components=12):\n",
    "    try:\n",
    "        # Read positive_transactions_parquet\n",
    "        positive_transactions_df = pd.read_parquet(positive_transactions_parquet)\n",
    "        \n",
    "        # Concatenate user_articles with userID and convert to DataFrame\n",
    "        user_data = pd.DataFrame([user_articles], columns=['article_1', 'article_2', 'article_3', 'article_4', 'article_5', 'article_6', 'article_7', 'article_8', 'article_9', 'article_10', 'article_11', 'article_12'])\n",
    "        user_data['customer_id'] = userID\n",
    "        \n",
    "        # Append user_data to positive_transactions_df\n",
    "        modified_df = pd.concat([positive_transactions_df, user_data], ignore_index=True)\n",
    "        \n",
    "        # Generate a user-item interaction matrix (sparse matrix)\n",
    "        user_item_matrix = modified_df.drop(columns=['customer_id']).apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "        \n",
    "        # Perform dimensionality reduction using Truncated SVD\n",
    "        svd = TruncatedSVD(n_components=n_components)\n",
    "        user_item_matrix_reduced = svd.fit_transform(user_item_matrix)\n",
    "        \n",
    "        # Compute similarity scores between the target user and all other users\n",
    "        similarity_scores = cosine_similarity(user_item_matrix_reduced, user_item_matrix_reduced[-1].reshape(1, -1))\n",
    "        \n",
    "        # Get indices of top 3 most similar users (excluding the user itself)\n",
    "        similar_user_indices = similarity_scores.argsort(axis=0)[-4:-1][::-1].flatten()\n",
    "        \n",
    "        # Retrieve customer IDs of top 3 most similar users\n",
    "        similar_users = positive_transactions_df.iloc[similar_user_indices].index.tolist()\n",
    "        \n",
    "        return similar_users\n",
    "    except Exception as e:\n",
    "        print(f'Error: {e}')\n",
    "        return []\n",
    "\n",
    "# Example usage:\n",
    "userID = '00000dbacae5abe5e23885899a1fa44253a17956c6d1c3d25f88aa139fdfc657'\n",
    "user_articles = ['0924243001', '0781758057', '0309864012', '0918522001', '0863646004', '0924243002', '', '', '', '', '', '']\n",
    "positive_transactions_parquet = 'positive_transactions.parquet'\n",
    "\n",
    "# Call the function\n",
    "similar_users = similar_user(userID, user_articles, positive_transactions_parquet)\n",
    "\n",
    "print(f\"Top 3 most similar users for customer {userID} based on their interactions:\")\n",
    "print(similar_users)\n",
    "\n",
    "\n",
    "\n",
    "# 0924243001 0781758057 0751471001 0309864012 0918522001 0863646004 0924243002 0872537006 0448509014 0562245001 0915529003 0842976005\n",
    "\n",
    "\n",
    "\n",
    "# 00000dbacae5abe5e23885899a1fa44253a17956c6d1c3d25f88aa139fdfc657,0924243001 0781758057 0751471001 0309864012 0918522001 0863646004 0924243002 0872537006 0448509014 0562245001 0915529003 0842976005\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               customer_id   article_1  \\\n",
      "0        00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...  0924243001   \n",
      "1        0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...  0924243001   \n",
      "2        000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...  0924243001   \n",
      "3        00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...  0924243001   \n",
      "4        00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...  0924243001   \n",
      "...                                                    ...         ...   \n",
      "1371975  ffffbbf78b6eaac697a8a5dfbfd2bfa8113ee5b403e474...  0924243001   \n",
      "1371976  ffffcd5046a6143d29a04fb8c424ce494a76e5cdf4fab5...  0924243001   \n",
      "1371977  ffffcf35913a0bee60e8741cb2b4e78b8a98ee5ff2e6a1...  0924243001   \n",
      "1371978  ffffd7744cebcf3aca44ae7049d2a94b87074c3d4ffe38...  0924243001   \n",
      "1371979  ffffd9ac14e89946416d80e791d064701994755c3ab686...  0924243001   \n",
      "\n",
      "          article_2   article_3   article_4   article_5   article_6  \\\n",
      "0        0781758057  0751471001  0309864012  0918522001  0863646004   \n",
      "1        0751471001  0918522001  0924243002  0448509014  0915529003   \n",
      "2        0914319002  0751471001  0894668003  0918522001  0810170016   \n",
      "3        0751471001  0918522001  0924243002  0448509014  0915529003   \n",
      "4        0751471001  0918522001  0924243002  0448509014  0915529003   \n",
      "...             ...         ...         ...         ...         ...   \n",
      "1371975  0896851001  0751471001  0372860002  0918522001  0916468003   \n",
      "1371976  0751471001  0918522001  0924243002  0448509014  0915529003   \n",
      "1371977  0751664001  0751471001  0902023002  0918522001  0111609001   \n",
      "1371978  0751471001  0918522001  0924243002  0448509014  0915529003   \n",
      "1371979  0751471001  0918522001  0924243002  0448509014  0915529003   \n",
      "\n",
      "          article_7   article_8   article_9  article_10  article_11  \\\n",
      "0        0924243002  0872537006  0448509014  0562245001  0915529003   \n",
      "1        0918292001  0714790020  0909370001  0866731001  0762846027   \n",
      "2        0924243002  0881691003  0448509014  0863646001  0915529003   \n",
      "3        0918292001  0714790020  0909370001  0866731001  0762846027   \n",
      "4        0918292001  0714790020  0909370001  0866731001  0762846027   \n",
      "...             ...         ...         ...         ...         ...   \n",
      "1371975  0924243002  0888732008  0448509014  0914071001  0915529003   \n",
      "1371976  0918292001  0714790020  0909370001  0866731001  0762846027   \n",
      "1371977  0924243002  0407653002  0448509014  0874754001  0915529003   \n",
      "1371978  0918292001  0714790020  0909370001  0866731001  0762846027   \n",
      "1371979  0918292001  0714790020  0909370001  0866731001  0762846027   \n",
      "\n",
      "         article_12  \n",
      "0        0842976005  \n",
      "1        0923758001  \n",
      "2        0933327001  \n",
      "3        0923758001  \n",
      "4        0923758001  \n",
      "...             ...  \n",
      "1371975  0751471026  \n",
      "1371976  0923758001  \n",
      "1371977  0899749004  \n",
      "1371978  0923758001  \n",
      "1371979  0923758001  \n",
      "\n",
      "[1371980 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Split the 'prediction' column into 12 different columns\n",
    "positive_transactions_df[['article_1', 'article_2', 'article_3', 'article_4', 'article_5', 'article_6', 'article_7', 'article_8', 'article_9', 'article_10', 'article_11', 'article_12']] = positive_transactions_df['prediction'].str.split(' ', expand=True)\n",
    "\n",
    "# Drop the original 'prediction' column\n",
    "positive_transactions_df.drop(columns=['prediction'], inplace=True)\n",
    "\n",
    "# Print the modified DataFrame\n",
    "print(positive_transactions_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
